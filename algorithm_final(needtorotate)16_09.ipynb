{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy #дает возможность сделать копию массива\n",
    "import graphviz as gv #библиотека визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:1079: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._set_labels(key, value)\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:1085: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._set_labels(key, value)\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/iliyashafirov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:120: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "Warning: node 'Заказ на поставку изменен эффективная стоимость', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен налоговые условия', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен уменьшена стоимость', graph '%3' size too small for label\n",
      "Warning: node 'Поступление материала-Получение-Завершающая поставка', graph '%3' size too small for label\n",
      "Warning: node 'Поступление материала-Получение-Частичная поставка', graph '%3' size too small for label\n",
      "Warning: node 'Счет заведен', graph '%3' size too small for label\n",
      "Warning: node 'Счет блокирован несоответствие даты', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен уменьшена цена', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку согласован 2', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен статус выпуска ДанныеСогл, измен не возможны', graph '%3' size too small for label\n",
      "Warning: node 'Поступление счета', graph '%3' size too small for label\n",
      "Warning: node 'Счет изменен условия оплаты', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен статус выпуска ДанныеОтпр, возможны изменения', graph '%3' size too small for label\n",
      "Warning: node 'Заявка изменена дата доставки', graph '%3' size too small for label\n",
      "Warning: node 'Счет изменен дата', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен запланированный срок доставки в днях', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен лимит на недопоставку', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен лимит на сверх-поставку', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен статус выпуска НачКод, возможны изменения', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку создан', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен увеличена цена', graph '%3' size too small for label\n",
      "Warning: node 'Платеж (выравнивание)', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен материал', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен увеличено количество', graph '%3' size too small for label\n",
      "Warning: node 'Заявка изменена количество', graph '%3' size too small for label\n",
      "Warning: node 'Заявка изменена закупочная организация', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку изменен увеличена стоимость', graph '%3' size too small for label\n",
      "Warning: node 'Создание Заявки', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку согласование отклонено', graph '%3' size too small for label\n",
      "Warning: node 'Заявка согласована', graph '%3' size too small for label\n",
      "Warning: node 'Счет блокирован несоответствие цены', graph '%3' size too small for label\n",
      "Warning: node 'Заказ на поставку согласован 1', graph '%3' size too small for label\n",
      "Warning: node 'Поступление материала-Возврат-Частичная поставка', graph '%3' size too small for label\n",
      "Warning: node 'Счет изменен налоговые условия', graph '%3' size too small for label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finalgraph.png'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Вычисление оптимального процента детализации графа бизнес-процесса\n",
    "\n",
    "#Подготовка данных к обработке\n",
    "df = pd.read_csv('Event_log.txt', sep='\\t', encoding='cp1251')\n",
    "df['Event end'] = pd.to_datetime(df['Event end'])\n",
    "df = df.sort_values(by='Event end')\n",
    "\n",
    "#Обработка данных: отбор закрытых кейсов\n",
    "started_cases = set(df.iloc[np.where(df['Activity Category'] == 'Заказ на поставку создан')]['CaseID'])\n",
    "finished_cases = set(df.iloc[np.where(df['Activity Category'] == 'Платеж (выравнивание)')]['CaseID'])\n",
    "finished = started_cases & finished_cases\n",
    "df['finished'] = df['CaseID'].apply(lambda x: x in finished)\n",
    "df = df[df['finished'] == 1]\n",
    "\n",
    "#Обработка данных: группировка событий в цепочки\n",
    "cases = df.groupby(['CaseID'])['Activity'].apply(lambda x: x.sum())\n",
    "cases = cases.reset_index()\n",
    "casesun = cases.drop_duplicates(subset=['Activity'])\n",
    "casesun['Newcount'] = casesun['Activity'].map(cases['Activity'].value_counts())\n",
    "caseval = casesun['CaseID']\n",
    "arrcase = df.groupby(['CaseID'])['Activity'].apply(list)\n",
    "arrcase = arrcase.reset_index()\n",
    "caseval = np.array(caseval)\n",
    "arrcaseun = arrcase.loc[arrcase['CaseID'].isin(caseval)]\n",
    "\n",
    "#Кластеризация: подготовка признаков\n",
    "arrcaseun['cluster'] = 0\n",
    "arrcaseun['unique'] = arrcaseun['Activity'].agg(pd.unique)\n",
    "arrcaseun['numactivities'] = arrcaseun['unique'].apply(lambda x: len(x))\n",
    "arrcaseun['reps'] = casesun['Newcount']\n",
    "\n",
    "#Кластеризация: реализация итеративного метода аномального кластера\n",
    "cur = arrcaseun[arrcaseun['cluster'] == 0]['numactivities'] #Кейсы, не принадлежащие аномальному кластеру, на текущей итерации\n",
    "i = 0\n",
    "therearenans = False\n",
    "while (len(cur) != 0):\n",
    "    i = i + 1\n",
    "    distances = np.zeros((len(cur),2)) #Разница между количеством событий в текущей цепочке и средним количеством событий оставшихся цепочек\n",
    "                                       #Разница между текущим количеством событий в цепочке и максимальным количеством событий по всем оставшимся цепочкам\n",
    "    centers = np.zeros(2) #Среднее значение количества событий в текущих цепочках\n",
    "                          #Максимальное значение количества событий в текущих цепочках\n",
    "    flag = True\n",
    "    zero = cur.mean()\n",
    "    centers[0] = zero \n",
    "    s = cur - zero\n",
    "    center = s.idxmax(s.apply(lambda x: np.linalg.norm(x)))\n",
    "    centers[1] = cur[center]\n",
    "    centers_old = np.zeros(centers.shape) #Среднее значение количества событий в цепочках, рассматриваемых на предыдущей итерации\n",
    "                                          #Максимальное значение количества событий в цепочках, рассматриваемых на предыдущей итерации\n",
    "    clusterser = pd.Series([])\n",
    "    if (therearenans == True):\n",
    "        break\n",
    "    while flag == True:\n",
    "        distances[:,0] = (cur - centers[0]).apply(lambda x: np.linalg.norm(x))\n",
    "        distances[:,1] = (cur - centers[1]).apply(lambda x: np.linalg.norm(x))\n",
    "        clusters = np.argmin(distances, axis = 1)\n",
    "        clusterser = pd.Series(clusters)\n",
    "        clusterser.index = cur.index\n",
    "        centers_old = deepcopy(centers)\n",
    "        centers[0] = np.mean(cur[clusters == 0], axis=0)\n",
    "        centers[1] = np.mean(cur[clusters == 1], axis=0)\n",
    "        error = np.linalg.norm(centers - centers_old)\n",
    "        if(np.isnan(centers).any() == True):\n",
    "            flag = False\n",
    "            therearenans = True\n",
    "        if (error == 0):\n",
    "            flag = False\n",
    "    new = clusterser[clusterser == 1]\n",
    "    arrcaseun['cluster'][new.index] = i\n",
    "    cur = arrcaseun[arrcaseun['cluster'] == 0]['numactivities']\n",
    "arrcaseun = arrcaseun.drop(cur.index, axis = 0)\n",
    "maxnumclust = max(arrcaseun['cluster']) #Количество аномальных кластеров\n",
    "\n",
    "#Кластеризация: отбор кластеров для визуализации\n",
    "qorclust = [] #Массив, содержащий количество  кейсов в кластере\n",
    "i = 1\n",
    "while i <= maxnumclust:\n",
    "    clust_i = arrcaseun['reps'][arrcaseun['cluster'] == i]\n",
    "    qorclust.append(sum(clust_i))\n",
    "    i += 1\n",
    "qormin = min(qorclust)\n",
    "qormax = max(qorclust)\n",
    "def f1(qormin, qormax, qor): #Функция нормирования количества кейсов в кластере\n",
    "    return (qor - qormin)/(qormax-qormin)\n",
    "T = [] #Массив, содержащий количество уникальных верщин в каждом кластере, которые не были рассмотрены на предыдущей итерации\n",
    "i = 2\n",
    "prev = set(arrcaseun['unique'][arrcaseun['cluster'] == 1].apply(pd.Series).stack().value_counts().index) #Множество вершин, содержащихся в предыдущих кластерах\n",
    "T.append(len(prev)) \n",
    "while i <= maxnumclust:\n",
    "    cur = arrcaseun['unique'][arrcaseun['cluster'] == i].apply(pd.Series).stack().value_counts()\n",
    "    unelems = set(cur.index)\n",
    "    newelems = unelems - prev #Вершины, которые не лежали в предыдущих кластерах\n",
    "    T.append(len(newelems))\n",
    "    prev = prev | newelems #Добавление нерасмотренных вершин во множество рассмотренных\n",
    "    i += 1\n",
    "arrcaseun['vis'] = 0\n",
    "arrcaseun['vis'][arrcaseun['cluster'] == 1] = 1\n",
    "def g1(T_min, T_max, t): #Функция нормирования количества кейсов в кластере\n",
    "    return (t - T_min)/(T_max-T_min)\n",
    "Tmin = min(T)\n",
    "Tmax = max(T)\n",
    "i = 2\n",
    "visclust = [] #Массив, содержащий количество кейсов в каждом из визуализированных кластеров\n",
    "visvert = [] #Массив, содерджащий количество уникальных вершин в каждом из визуализированных кластеров\n",
    "visclust.append(qorclust[0])\n",
    "visvert.append(T[0])\n",
    "while((f1(qormin, qormax, qorclust[i-1]) + g1(Tmin, Tmax, T[i-1])) >(f1(qormin, sum(qorclust), sum(visclust)) + g1(Tmin, sum(T), sum(visvert)))): \n",
    "    arrcaseun['vis'][arrcaseun['cluster'] == i] = 1\n",
    "    visclust.append(qorclust[i-1])\n",
    "    visvert.append(T[i-1])\n",
    "    i+=1\n",
    "\n",
    "#Подготовка к визуализации: отбор кейсов для визуализации\n",
    "visualize = arrcaseun[arrcaseun['vis'] == 1]\n",
    "\n",
    "#Подготовка к визуализации: удаление двоеточий в названиях событий и уникальных событий для корректной работы библиотеки визуализации\n",
    "for i in (visualize['Activity'].index):\n",
    "    visualize['Activity'][i] = [w.replace(':', '') for w in visualize['Activity'][i]]\n",
    "for i in (visualize['unique'].index):\n",
    "    visualize['unique'][i] = [w.replace(':', '') for w in visualize['unique'][i]]\n",
    "    \n",
    "#Подготовка к визуализации: отбор вершин для визуализации\n",
    "vertices = visualize['unique'].apply(pd.Series).stack().value_counts().index\n",
    "\n",
    "arrs = []\n",
    "\n",
    "#Подготовка к визуализации: создание множества ребер графа\n",
    "for i in visualize['Activity'].index:\n",
    "    arrs.append(list(zip(visualize['Activity'][i][:-1], visualize['Activity'][i][1:])))\n",
    "    \n",
    "\n",
    "#Подготовка к визуализации: удаление параллельных ребер между двумя вершинами\n",
    "edges = set(arrs[0])\n",
    "for i in range(len(arrs[:int(len(arrs)/30)])):\n",
    "    edges = edges.union(arrs[i])\n",
    "    \n",
    "#Подготовка к визуализации: построение графа\n",
    "graph = gv.Digraph(format=\"png\")\n",
    "graph.node_attr.update(color = 'lightblue', style = 'filled', fixedsize = 'true')\n",
    "graph.attr(size='40,12')\n",
    "for edge in edges:\n",
    "    graph.node(edge[0],label= edge[0],  shape=\"circle\", color=\"#F3BE26\")\n",
    "    graph.node(edge[1], label=edge[1], shape=\"circle\", color=\"#F3BE26\")\n",
    "    graph.edge(edge[0], edge[1])\n",
    "graph.render(\"finalgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
